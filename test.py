"""
Script de Prueba para el Modelo de PredicciÃ³n de Temperatura

Este script:
1. Carga un modelo previamente entrenado
2. Permite hacer predicciones con datos nuevos
3. Muestra ejemplos de uso interactivo
"""

import numpy as np
import pickle
import os
from data_loader import WeatherDataLoader
from neural_network import NeuralNetwork


def load_model(filepath):
    """
    Carga un modelo guardado.
    
    Args:
        filepath: Ruta al archivo .pkl del modelo
        
    Returns:
        nn: Red neuronal cargada
    """
    if not os.path.exists(filepath):
        raise FileNotFoundError(f"No se encontrÃ³ el modelo en: {filepath}")
    
    with open(filepath, 'rb') as f:
        nn = pickle.load(f)
    
    print(f"âœ… Modelo cargado desde: {filepath}")
    print(f"   Arquitectura: {nn.n_inputs} â†’ {nn.n_hidden} â†’ 1")
    print(f"   Ã‰pocas entrenadas: {len(nn.loss_history)}")
    
    return nn


def predict_with_manual_input(nn, scaler):
    """
    Permite hacer predicciones ingresando datos manualmente.
    
    Args:
        nn: Red neuronal entrenada
        scaler: Normalizador usado en entrenamiento
    """
    print("\n" + "="*60)
    print("ğŸ”® PREDICCIÃ“N INTERACTIVA")
    print("="*60)
    
    print("\nIngresa los datos de los Ãºltimos 3 meses:")
    print("(T2M = temperatura promedio, MAX = temperatura mÃ¡xima, MIN = temperatura mÃ­nima)")
    
    features = []
    
    for mes in range(1, 4):
        print(f"\n--- Mes {mes} ---")
        
        t2m = float(input(f"  T2M promedio (Â°C): "))
        t2m_max = float(input(f"  T2M_MAX (Â°C): "))
        t2m_min = float(input(f"  T2M_MIN (Â°C): "))
        
        features.extend([t2m, t2m_max, t2m_min])
    
    # Convertir a array y normalizar
    X = np.array(features).reshape(1, -1)
    X_normalized = scaler.transform(X)
    
    # Predecir
    prediction = nn.predict(X_normalized)
    
    print("\n" + "-"*60)
    print(f"ğŸŒ¡ï¸  PREDICCIÃ“N: {prediction[0][0]:.2f}Â°C")
    print("-"*60)
    
    # Mostrar contexto
    avg_temp = np.mean([features[i] for i in range(0, 9, 3)])
    print(f"\nğŸ“Š Contexto:")
    print(f"   Temperatura promedio de los 3 meses: {avg_temp:.2f}Â°C")
    print(f"   PredicciÃ³n para el mes siguiente: {prediction[0][0]:.2f}Â°C")
    
    if prediction[0][0] > avg_temp:
        print(f"   â†’ La temperatura aumentarÃ¡ ~{prediction[0][0] - avg_temp:.2f}Â°C")
    else:
        print(f"   â†’ La temperatura disminuirÃ¡ ~{avg_temp - prediction[0][0]:.2f}Â°C")


def predict_from_dataset(nn, data_path, n_examples=5):
    """
    Hace predicciones sobre ejemplos del dataset.
    
    Args:
        nn: Red neuronal entrenada
        data_path: Ruta al dataset
        n_examples: NÃºmero de ejemplos a mostrar
    """
    print("\n" + "="*60)
    print("ğŸ“Š PREDICCIONES SOBRE DATASET REAL")
    print("="*60)
    
    # Cargar datos
    loader = WeatherDataLoader(filepath=data_path, n_months_history=3)
    X_train, X_test, y_train, y_test = loader.load_and_prepare()
    
    # Hacer predicciones en test set
    y_pred = nn.predict(X_test)
    
    # Calcular mÃ©tricas
    metrics = nn.evaluate(X_test, y_test)
    
    print(f"\nğŸ“ˆ MÃ©tricas en Test Set:")
    print(f"   RMSE: {metrics['RMSE']:.2f}Â°C")
    print(f"   MAE:  {metrics['MAE']:.2f}Â°C")
    print(f"   RÂ²:   {metrics['R2']:.4f}")
    
    # Mostrar ejemplos individuales
    print(f"\nğŸ” Ejemplos de Predicciones (primeros {n_examples}):")
    print("-"*60)
    
    for i in range(min(n_examples, len(X_test))):
        real = y_test[i]
        pred = y_pred[i][0]
        error = pred - real
        
        print(f"\nEjemplo {i+1}:")
        print(f"   Real:      {real:.2f}Â°C")
        print(f"   Predicho:  {pred:.2f}Â°C")
        print(f"   Error:     {error:+.2f}Â°C", end="")
        
        # Indicador visual del error
        if abs(error) < 1.0:
            print(" âœ… (excelente)")
        elif abs(error) < 2.0:
            print(" ğŸ‘ (bueno)")
        elif abs(error) < 3.0:
            print(" âš ï¸  (aceptable)")
        else:
            print(" âŒ (mejorable)")


def analyze_worst_predictions(nn, data_path, n_worst=5):
    """
    Analiza las peores predicciones para entender errores del modelo.
    
    Args:
        nn: Red neuronal entrenada
        data_path: Ruta al dataset
        n_worst: NÃºmero de peores casos a mostrar
    """
    print("\n" + "="*60)
    print("ğŸ” ANÃLISIS DE PEORES PREDICCIONES")
    print("="*60)
    
    # Cargar datos
    loader = WeatherDataLoader(filepath=data_path, n_months_history=3)
    X_train, X_test, y_train, y_test = loader.load_and_prepare()
    
    # Predicciones
    y_pred = nn.predict(X_test)
    
    # Calcular errores absolutos
    errors = np.abs((y_pred - y_test.reshape(-1, 1))).flatten()
    
    # Encontrar los peores casos
    worst_indices = np.argsort(errors)[-n_worst:][::-1]
    
    print(f"\nâŒ Top {n_worst} Peores Predicciones:")
    print("-"*60)
    
    for rank, idx in enumerate(worst_indices, 1):
        real = y_test[idx]
        pred = y_pred[idx][0]
        error = pred - real
        
        print(f"\n#{rank} - Error absoluto: {abs(error):.2f}Â°C")
        print(f"   Real:      {real:.2f}Â°C")
        print(f"   Predicho:  {pred:.2f}Â°C")
        print(f"   Error:     {error:+.2f}Â°C")
        
        # Datos de entrada (desnormalizados estarÃ­an mejor, pero es complejo)
        print(f"   Entrada: {X_test[idx][:3]} ... (primeros 3 valores)")


def compare_with_simple_baseline(nn, data_path):
    """
    Compara el modelo con estrategias simples (baseline).
    
    Args:
        nn: Red neuronal entrenada
        data_path: Ruta al dataset
    """
    print("\n" + "="*60)
    print("âš–ï¸  COMPARACIÃ“N CON BASELINES")
    print("="*60)
    
    # Cargar datos
    loader = WeatherDataLoader(filepath=data_path, n_months_history=3)
    X_train, X_test, y_train, y_test = loader.load_and_prepare()
    
    # PredicciÃ³n del modelo
    y_pred = nn.predict(X_test)
    model_mse = np.mean((y_pred.flatten() - y_test) ** 2)
    
    # Baseline 1: Siempre predecir el promedio
    baseline_mean = np.mean(y_train)
    baseline1_mse = np.mean((baseline_mean - y_test) ** 2)
    
    # Baseline 2: Predecir el Ãºltimo valor conocido (persistencia)
    # Usamos el Ãºltimo valor de cada secuencia de entrada
    last_values = X_train[:, 0]  # Primera caracterÃ­stica (T2M del Ãºltimo mes)
    baseline2_mse = np.mean((np.mean(last_values) - y_test) ** 2)
    
    print("\nğŸ“Š ComparaciÃ³n de MSE:")
    print(f"\n   1ï¸âƒ£  Baseline (predecir promedio):")
    print(f"       MSE = {baseline1_mse:.4f}")
    
    print(f"\n   2ï¸âƒ£  Baseline (persistencia):")
    print(f"       MSE = {baseline2_mse:.4f}")
    
    print(f"\n   3ï¸âƒ£  Nuestro Modelo (Red Neuronal):")
    print(f"       MSE = {model_mse:.4f}")
    
    # Mejora porcentual
    improvement1 = ((baseline1_mse - model_mse) / baseline1_mse) * 100
    improvement2 = ((baseline2_mse - model_mse) / baseline2_mse) * 100
    
    print(f"\nğŸ¯ Mejora respecto a baselines:")
    print(f"   vs Promedio: {improvement1:+.2f}%")
    print(f"   vs Persistencia: {improvement2:+.2f}%")
    
    if improvement1 > 0 and improvement2 > 0:
        print(f"\nâœ… Â¡El modelo supera ambos baselines!")
    elif improvement1 > 0:
        print(f"\nâš ï¸  El modelo solo supera al baseline de promedio")
    else:
        print(f"\nâŒ El modelo no supera los baselines. Necesita mejora.")


def main():
    """
    FunciÃ³n principal con menÃº interactivo.
    """
    print("="*60)
    print("ğŸ§ª PRUEBA DEL MODELO DE PREDICCIÃ“N DE TEMPERATURA")
    print("="*60)
    
    # Buscar modelos disponibles
    models = [f for f in os.listdir('.') if f.endswith('.pkl') and f.startswith('modelo_temperatura')]
    
    if not models:
        print("\nâŒ No se encontraron modelos entrenados.")
        print("ğŸ’¡ Primero ejecuta 'train.py' para entrenar un modelo.")
        return
    
    # Seleccionar modelo
    print(f"\nğŸ“‚ Modelos disponibles:")
    for i, model in enumerate(models, 1):
        size = os.path.getsize(model) / 1024
        print(f"   {i}. {model} ({size:.2f} KB)")
    
    if len(models) == 1:
        selected_model = models[0]
        print(f"\nâ†’ Usando: {selected_model}")
    else:
        choice = int(input(f"\nSelecciona un modelo (1-{len(models)}): "))
        selected_model = models[choice - 1]
    
    # Cargar modelo
    nn = load_model(selected_model)
    
    # MenÃº de opciones
    while True:
        print("\n" + "="*60)
        print("ğŸ“‹ MENÃš DE OPCIONES")
        print("="*60)
        print("\n1. PredicciÃ³n interactiva (ingresar datos manualmente)")
        print("2. Predicciones sobre dataset real")
        print("3. Analizar peores predicciones")
        print("4. Comparar con baselines")
        print("5. Salir")
        
        choice = input("\nSelecciona una opciÃ³n (1-5): ")
        
        if choice == '1':
            # Necesitamos el scaler del DataLoader
            data_path = 'southamerica_0_regional_monthly.csv'
            if not os.path.exists(data_path):
                print(f"\nâŒ No se encontrÃ³ el dataset: {data_path}")
                continue
            
            loader = WeatherDataLoader(filepath=data_path, n_months_history=3)
            X_train, X_test, y_train, y_test = loader.load_and_prepare()
            
            predict_with_manual_input(nn, loader.scaler)
            
        elif choice == '2':
            data_path = 'southamerica_0_regional_monthly.csv'
            if not os.path.exists(data_path):
                print(f"\nâŒ No se encontrÃ³ el dataset: {data_path}")
                continue
            predict_from_dataset(nn, data_path)
            
        elif choice == '3':
            data_path = 'southamerica_0_regional_monthly.csv'
            if not os.path.exists(data_path):
                print(f"\nâŒ No se encontrÃ³ el dataset: {data_path}")
                continue
            analyze_worst_predictions(nn, data_path)
            
        elif choice == '4':
            data_path = 'southamerica_0_regional_monthly.csv'
            if not os.path.exists(data_path):
                print(f"\nâŒ No se encontrÃ³ el dataset: {data_path}")
                continue
            compare_with_simple_baseline(nn, data_path)
            
        elif choice == '5':
            print("\nğŸ‘‹ Â¡Hasta luego!")
            break
        
        else:
            print("\nâŒ OpciÃ³n invÃ¡lida. Intenta de nuevo.")


if __name__ == "__main__":
    main()